{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MET 585 (Cloud Physics) Course Project (NIU)\n",
    "## An Analysis of the Climatological Trend in Mid-Latitude Baroclinity\n",
    "## Robert C. Fritzen\n",
    "\n",
    "### Synopsis\n",
    "Barocliic Instability (Baroclinity) is one of the fundamental foci of the development of extratropical cyclones in the mid-latitudes. Defined as the growth of small scale disturbances through time, baroclinity is expressed as a reinforcing interaction of wind shear at different levels of the atmosphere. As the Thermal Wind relationship connects surface temperature gradients to wind shear, we can define baroclinity using the Brunt-Väisälä Frequency:\n",
    "\n",
    "<font size=4>\n",
    "$\\sigma_{BI} = \\frac{f}{N}\\frac{d\\vec{V}}{dZ}$\n",
    "</font>\n",
    "\n",
    "Which defines: The coriolis parameter (f), the Brunt-Väisälä Oscillation Frequency (N), and the wind shear vector with respect to geopotential height ($\\frac{d\\vec{V}}{dZ}$)\n",
    "\n",
    "Using the definition of the Brunt-Väisälä Oscillation Frequency, $N = \\sqrt{\\frac{g}{\\theta}\\frac{\\partial\\theta}{{\\partial}Z}}$, The previous formula can be expanded to:\n",
    "\n",
    "<font size=4>\n",
    "$\\sigma_{BI} = \\frac{f}{\\sqrt{\\frac{g}{{\\theta}_m}\\frac{{\\theta}_u - {\\theta}_l}{Z_u - Z_l}}}\\frac{d\\vec{V}}{dZ} $\n",
    "</font>\n",
    "\n",
    "Which defines a change in the potential temperature (${\\theta}$), with respect to height. By differential approximation methods, we analyze this as a change between the upper and lower analysis levels.\n",
    "\n",
    "This project seeks to explore the climatological trend in baroclinity over the past 70 years. Using the NCEP/NCAR Reanalysis Data, baroclinity can be calculated at three different levels (Low, Middle, and Upper) and then explored using statisical tools such as standard anomaly and moving averages to explore how baroclinity is changing with time.\n",
    "\n",
    "It is hypothesized that under climate change scenarios, the meridional (Y) temperature gradient is weakening, and hence the low level temperature gradient is also weakening, reducing baroclinity with time.\n",
    "\n",
    "### Python\n",
    "This notebook was written with Anaconda 2, using various scientific analysis packages. To run this notebook you will need to install the following packages:\n",
    "\n",
    "* numpy\n",
    "* matplotlib\n",
    "* Basemap\n",
    "* scipy (stats module)\n",
    "* netCDF4\n",
    "* ftplib\n",
    "\n",
    "This notebook was constructed with sequential execution in mind. Run the code blocks in the order they are presented as each block requires the next in order to execute completely, this was done for organizational purposes and to keep things as neat as possible for readability and replication purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Required Packages\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import scipy.stats as stats\n",
    "from netCDF4 import Dataset\n",
    "import os\n",
    "from ftplib import FTP\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Constants and Variables\n",
    "\n",
    "# Plotting Commands\n",
    "make_average_monthly_plots = True\n",
    "make_average_yearly_plots = True\n",
    "make_difference_plots = True\n",
    "make_mean_compare_plots = True\n",
    "make_standard_anomaly_plots = True\n",
    "make_moving_average_plots = True\n",
    "make_moving_difference_plots = True\n",
    "\n",
    "# Storage Variables\n",
    "storePath = \"D:/Robert Docs/College/NIU/MET 585/Project/\"\n",
    "dataPath = storePath + \"Data/\"\n",
    "plotPath = storePath + \"Plots/\"\n",
    "\n",
    "p_anom_low = plotPath + \"anom_low/\"\n",
    "p_amon_mid = plotPath + \"anom_mid/\"\n",
    "p_anom_up = plotPath + \"anom_up/\"\n",
    "p_avg_low_mo = plotPath + \"avg_low_month/\"\n",
    "p_avg_mid_mo = plotPath + \"avg_mid_month/\"\n",
    "p_avg_up_mo = plotPath + \"avg_up_month/\"\n",
    "p_avg_low_ye = plotPath + \"low_year/\"\n",
    "p_avg_mid_ye = plotPath + \"mid_year/\"\n",
    "p_avg_up_ye = plotPath + \"up_year/\"\n",
    "p_d_low_mo = plotPath + \"d_low_month/\"\n",
    "p_d_mid_mo = plotPath + \"d_mid_month/\"\n",
    "p_d_up_mo = plotPath + \"d_up_month/\"\n",
    "p_d_low_ye = plotPath + \"d_low_year/\"\n",
    "p_d_mid_ye = plotPath + \"d_mid_year/\"\n",
    "p_d_up_ye = plotPath + \"d_up_year/\"\n",
    "p_mean_c_l = plotPath + \"low_mean_comp/\"\n",
    "p_mean_c_m = plotPath + \"mid_mean_comp/\"\n",
    "p_mean_c_u = plotPath + \"up_mean_comp/\"\n",
    "p_mov_low = plotPath + \"moving_avg_low/\"\n",
    "p_mov_mid = plotPath + \"moving_avg_mid/\"\n",
    "p_mov_up = plotPath + \"moving_avg_up/\"\n",
    "p_dmov_low = plotPath + \"d_moving_avg_low/\"\n",
    "p_dmov_mid = plotPath + \"d_moving_avg_mid/\"\n",
    "p_dmov_up = plotPath + \"d_moving_avg_up/\"\n",
    "\n",
    "monthPaths = [\"january/\", \"february/\", \"march/\", \"april/\", \"may/\", \n",
    "              \"june/\", \"july/\", \"august/\", \"september/\", \"october/\", \n",
    "              \"november/\", \"december/\"]\n",
    "\n",
    "#ensoTable: Defines the ENSO phase for that year (-1: LAN, 0: NEU, 1: ELN), note 1948-49 are not present in the CPC\n",
    "#            records, so they are assumed neutral\n",
    "ensoTable = [0, 0, -1, 1, 0, 1, -1, -1, -1, 1, 1, 0, 0, 0, 0, 1, \n",
    "            #1964\n",
    "             -1, 1, 0, 0, 0, 1, -1, -1, 1, -1, -1, -1, 0, 1, 0, 0,\n",
    "            #1980\n",
    "            0, 0, 1, 1, 0, -1, 0, 1, -1, -1, 0, 1, 1, 0, 1, -1, -1,\n",
    "            #1997\n",
    "            1, 1, -1, -1, 0, 1, 0, 1, 0, 0, -1, -1, 1, -1, -1, 0,\n",
    "            #2013\n",
    "            0, 0, 1, 1, 0]\n",
    "\n",
    "linkBase = \"ftp://ftp.cdc.noaa.gov/Datasets/ncep.reanalysis/pressure/\" #air.yyyy.nc, hgt.yyyy.nc, uwnd.yyyy.nc, vwnd.yyyy.nc\n",
    "years = np.arange(1948, 2018, 1) # Stop at 2017, 2018 is \"in progress\", so we'll exclude\n",
    "hoursPerDay = 4 # Four daily observations per ncep file (0z, 6z, 12z, and 18z)\n",
    "\n",
    "# Meteorological Constants\n",
    "Omega = 7.29 * (10**-5)\n",
    "TwoOmega = 2 * Omega\n",
    "ROverCp = 287./1004\n",
    "gConst = 9.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Required Functions\n",
    "\n",
    "# calc_theta(T, P):\n",
    "## Calculate potential temperature using poisson's equation\n",
    "## Variables: T - Temperature (Kelvin), P - Pressure (Pascals)\n",
    "## Returns: Theta - Potential Temperature (Kelvin)\n",
    "def calc_theta(T, P):\n",
    "    return T * (1000 / P) ** ROverCp\n",
    "\n",
    "# Functions\n",
    "def paired_t_test(a, b):\n",
    "    at = np.array(a)\n",
    "    bt = np.array(b)\n",
    "\n",
    "    y,x = at.shape\n",
    "    stat = np.zeros((y, x))\n",
    "    pvalue = np.zeros((y, x))\n",
    "    for yy in range(y):\n",
    "        for xx in range(x):\n",
    "            stat[yy,xx],pvalue[yy,xx] = stats.ttest_ind(at[yy,xx], bt[yy,xx], nan_policy=\"omit\")\n",
    "    #stat,pvalue = stats.ttest_ind(at, bt, nan_policy=\"omit\")\n",
    "    return tuple((stat,pvalue)) \n",
    "\n",
    "# prepareMap()\n",
    "## Generate a basemap plot with the plotting location defined.\n",
    "## Returns: m - Basemap object \n",
    "def prepareMap():\n",
    "    plt.figure()\n",
    "    m = Basemap(projection='mill',llcrnrlon=0,llcrnrlat=10,urcrnrlon=360,urcrnrlat=80)\n",
    "    m.drawcoastlines()\n",
    "    m.drawstates()\n",
    "    m.drawcountries()\n",
    "    m.drawmapboundary()\n",
    "    return m\n",
    "\n",
    "def makeBCIPlot(baroclinic, title, savePath):\n",
    "    BI_F=np.flipud(baroclinic)\n",
    "    m = prepareMap()\n",
    "\n",
    "    pRange = np.linspace(1e-5, 4, 40, endpoint=True)\n",
    "    #cs = m.contour(lon, lat, BI, pRange, linewidths=0.5, colors='k')\n",
    "    ny = BI_F.shape[0] \n",
    "    nx = BI_F.shape[1]\n",
    "    lons, lats = m.makegrid(nx, ny)\n",
    "    x, y = m(lons, lats)\n",
    "    cs = m.contourf(x, y, BI_F, pRange, cmap=plt.cm.jet)\n",
    "    cbar = m.colorbar(cs, location='bottom', pad=\"5%\")\n",
    "    cbar.set_label('s^-1 (E-6)')    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "    \n",
    "    plt.savefig(savePath, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Plot saved: \" + savePath)\n",
    "    \n",
    "#d_Plot(): 2 - 1 (Red: Decrease, Blue: Increase)\n",
    "def make_D_BCIPlot(baroclinic1, baroclinic2, title, savePath):\n",
    "    BI_1=np.flipud(baroclinic1)\n",
    "    BI_2=np.flipud(baroclinic2)\n",
    "    BI_F = BI_2 - BI_1\n",
    "    m = prepareMap()\n",
    "\n",
    "    pRange = np.linspace(-0.5, 0.5, 40, endpoint=True)\n",
    "    #cs = m.contour(lon, lat, BI, pRange, linewidths=0.5, colors='k')\n",
    "    ny = BI_F.shape[0] \n",
    "    nx = BI_F.shape[1]\n",
    "    lons, lats = m.makegrid(nx, ny)\n",
    "    x, y = m(lons, lats)\n",
    "    cs = m.contourf(x, y, BI_F, pRange, cmap=plt.cm.RdBu)\n",
    "    cbar = m.colorbar(cs, location='bottom', pad=\"5%\")\n",
    "    cbar.set_label('s^-1 (E-6)')    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "    \n",
    "    plt.savefig(savePath, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Plot saved: \" + savePath)    \n",
    "\n",
    "def make_anom_BCIPlot(stdAnomaly, title, savePath):\n",
    "    BI_F=np.flipud(stdAnomaly)\n",
    "    m = prepareMap()\n",
    "\n",
    "    pRange = np.linspace(-3, 3, 40, endpoint=True)\n",
    "    #cs = m.contour(lon, lat, BI, pRange, linewidths=0.5, colors='k')\n",
    "    ny = BI_F.shape[0] \n",
    "    nx = BI_F.shape[1]\n",
    "    lons, lats = m.makegrid(nx, ny)\n",
    "    x, y = m(lons, lats)\n",
    "    cs = m.contourf(x, y, BI_F, pRange, cmap=plt.cm.RdBu)\n",
    "    cbar = m.colorbar(cs, location='bottom', pad=\"5%\")\n",
    "    cbar.set_label('s^-1 (E-6)')    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "    \n",
    "    plt.savefig(savePath, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Plot saved: \" + savePath)\n",
    "    \n",
    "def make_mean_compare_BCIPlot(mean, baroclinic, title, savePath, withStats = True):    \n",
    "    BI_1=np.flipud(mean)\n",
    "    BI_2=np.flipud(baroclinic)\n",
    "    BI_F = BI_2 - BI_1 \n",
    "    \n",
    "    m = prepareMap()\n",
    "\n",
    "    pRange = np.linspace(-1, 1, 40, endpoint=True)\n",
    "    #cs = m.contour(lon, lat, BI, pRange, linewidths=0.5, colors='k')\n",
    "    ny = BI_F.shape[0] \n",
    "    nx = BI_F.shape[1]\n",
    "    lons, lats = m.makegrid(nx, ny)\n",
    "    x, y = m(lons, lats)\n",
    "    cs = m.contourf(x, y, BI_F, pRange, cmap=plt.cm.RdBu)\n",
    "    if(withStats):\n",
    "        tStat, pvalue = paired_t_test(BI_1, BI_2)\n",
    "        critu1cs = plt.contour(x, y, tStat, levels=[2,977], cmap=plt.get_cmap('gray'), linestyles='dashed')\n",
    "    \n",
    "    cbar = m.colorbar(cs, location='bottom', pad=\"5%\")\n",
    "    cbar.set_label('s^-1 (E-6)')    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "    \n",
    "    plt.savefig(savePath, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Plot saved: \" + savePath)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FTP Code Block\n",
    "The following code block will download the NCEP/NCAR Reanalysis Files from the CDC NOAA Page (ftp.cdc.noaa.gov). This server accepts anonomous logins, and therefore we can use the FTPLib package to download the files. I chose this over urllib as urllib has a caching problem after downloading a single file from FTP servers that can cause additional downloads to corrupt. As we're dowloading 4 * n(years) files, that are each ~500MB large, this can be problematic.\n",
    "\n",
    "The file storage for our particular dataset is located in: /Datasets/ncep.reanalysis/pressure/ and has a naming format as such:\n",
    "\n",
    "* Air Temperature: air.yyyy.nc\n",
    "* Geopotential Height: hgt.yyyy.nc\n",
    "* Zonal Wind: uwnd.yyyy.nc\n",
    "* Meridional Wind: vwnd.yyyy.nc\n",
    "\n",
    "Once the four files for a single year are collected, baroclinity is calculated for SFC-850mb, 850mb - 500mb, and 700mb - 300mb and stored into a single NetCDF file named baroclinic.yyyy.nc in the same directory. The original NCEP files are then removed from your computer to preserve storage space (~1.5GB for the four files vs ~90MB for the single baroclinic file)\n",
    "\n",
    "**NOTE: Running this code block will take A LONG TIME, you are downloading 70 years of data and performing calculations on these data as the downloads are being completed, it took my laptop about 15 hours to complete the full download and calculation processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ftp = FTP('ftp.cdc.noaa.gov')\n",
    "ftp.login()\n",
    "\n",
    "print(\"Beginning collection of NETCDF files (THIS WILL TAKE A LONG TIME)\")\n",
    "for y in years:\n",
    "    print(\"Beginning Collection for \" + str(y))\n",
    "    tLink = \"/Datasets/ncep.reanalysis/pressure/air.\" + str(y) + \".nc\"\n",
    "    hLink = \"/Datasets/ncep.reanalysis/pressure/hgt.\" + str(y) + \".nc\"\n",
    "    uLink = \"/Datasets/ncep.reanalysis/pressure/uwnd.\" + str(y) + \".nc\"\n",
    "    vLink = \"/Datasets/ncep.reanalysis/pressure/vwnd.\" + str(y) + \".nc\" \n",
    "    \n",
    "    print(\"Downloading air temperature, storing in tmp.air.nc\")\n",
    "    \n",
    "    localfile1 = open(dataPath + \"tmp.air.nc\", 'wb')\n",
    "    ftp.retrbinary('RETR ' + tLink, localfile1.write, 1024)\n",
    "    localfile1.close()    \n",
    "    \n",
    "    print(\"Downloading height, storing in tmp.hgt.nc\")\n",
    "    localfile2 = open(dataPath + \"tmp.hgt.nc\", 'wb')\n",
    "    ftp.retrbinary('RETR ' + hLink, localfile2.write, 1024)\n",
    "    localfile2.close() \n",
    "    \n",
    "    print(\"Downloading u winds, storing in tmp.uwnd.nc\")\n",
    "    localfile3 = open(dataPath + \"tmp.uwnd.nc\", 'wb')\n",
    "    ftp.retrbinary('RETR ' + uLink, localfile3.write, 1024)\n",
    "    localfile3.close() \n",
    "    \n",
    "    print(\"Downloading v winds, storing in tmp.vwnd.nc\")\n",
    "    localfile4 = open(dataPath + \"tmp.vwnd.nc\", 'wb')\n",
    "    ftp.retrbinary('RETR ' + vLink, localfile4.write, 1024)\n",
    "    localfile4.close() \n",
    "    \n",
    "    print(\"Downloads complete, opening netCDF files\")\n",
    "    \n",
    "    aTmp = Dataset(dataPath + \"tmp.air.nc\")\n",
    "    hTmp = Dataset(dataPath + \"tmp.hgt.nc\")\n",
    "    uTmp = Dataset(dataPath + \"tmp.uwnd.nc\")\n",
    "    vTmp = Dataset(dataPath + \"tmp.vwnd.nc\")\n",
    "    \n",
    "    outFile = dataPath + \"baroclinic.\" + str(y) + \".nc\"\n",
    "    newNCFile = Dataset(outFile, 'w', format='NETCDF4_CLASSIC')\n",
    "    time = newNCFile.createDimension('time', size=None) \n",
    "    lat = newNCFile.createDimension('lat', 33)\n",
    "    lon = newNCFile.createDimension('lon', 144)  \n",
    "    \n",
    "    ll_BCI = newNCFile.createVariable('BCI_Low', np.float32, ('time','lat','lon'))\n",
    "    ml_BCI = newNCFile.createVariable('BCI_Mid', np.float32, ('time','lat','lon'))   \n",
    "    ul_BCI = newNCFile.createVariable('BCI_Hi', np.float32, ('time','lat','lon'))   \n",
    "    \n",
    "    print(\"Begin Baroclinic Calculations\")\n",
    "    \n",
    "    # Note, we only want latitudes between 5N and 85N ( 2->35 )\n",
    "    T = np.squeeze(aTmp.variables['air'][:,:,2:35,:]) \n",
    "    U = np.squeeze(uTmp.variables['uwnd'][:,:,2:35,:])\n",
    "    V = np.squeeze(vTmp.variables['vwnd'][:,:,2:35,:])\n",
    "    H = np.squeeze(hTmp.variables['hgt'][:,:,2:35,:])\n",
    "    wVel = (U**2 + V**2)**0.5\n",
    "    \n",
    "    lat = np.linspace(5,85,33)\n",
    "    lon = np.linspace(-177.5,180,144)\n",
    "    p = aTmp.variables['level'][:] # Grab the isobaric levels\n",
    "    \n",
    "    itime = len(aTmp.variables['time'][:]) \n",
    "    ilat = len(lat)\n",
    "    ilon = len(lon)    \n",
    "    \n",
    "    f = TwoOmega * np.sin(lat * (np.pi / 180))\n",
    "    # Construct a \"coriolis\" array of equivalent size to the other arrays\n",
    "    corPar = np.zeros((itime, 1, 1, ilat, ilon))\n",
    "    for i,l in enumerate(lat):\n",
    "        corPar[:,0,0,i,:] = f[np.where(lat == l)]    \n",
    "    \n",
    "    print(\"Calculating Low Level Baroclinity\")\n",
    "    # Low Level: 1000, 850, 700\n",
    "    low = 1000\n",
    "    med = 850\n",
    "    high = 700\n",
    "    \n",
    "    wVelLow = wVel[:,np.where(p==low),:,:]\n",
    "    wVelHigh = wVel[:,np.where(p==high),:,:]  \n",
    "    geoHgtLow = H[:,np.where(p==low),:,:]\n",
    "    geoHgtHigh = H[:,np.where(p==high),:,:]    \n",
    "    thetaLow = calc_theta(T[:,np.where(p==low),:,:], low)\n",
    "    thetaMid = calc_theta(T[:,np.where(p==med),:,:], med)\n",
    "    thetaHi = calc_theta(T[:,np.where(p==high),:,:], high)\n",
    "    \n",
    "    dTheta = thetaHi - thetaLow\n",
    "    dZ = geoHgtHigh - geoHgtLow\n",
    "    rootTerm = np.sqrt((gConst / thetaMid) * (dTheta / dZ))\n",
    "    outerTerm = (wVelHigh - wVelLow) / dZ  \n",
    "    BI = 0.31 * (corPar / rootTerm) * (outerTerm) * 100000    \n",
    "    ll_BCI[:] = BI[:,0,0,:,:]   \n",
    "    \n",
    "    print(\"Calculating Mid Level Baroclinity\")\n",
    "    # Mid Level: 850, 700, 500\n",
    "    low = 850\n",
    "    med = 700\n",
    "    high = 500\n",
    "    \n",
    "    wVelLow = wVel[:,np.where(p==low),:,:]\n",
    "    wVelHigh = wVel[:,np.where(p==high),:,:]  \n",
    "    geoHgtLow = H[:,np.where(p==low),:,:]\n",
    "    geoHgtHigh = H[:,np.where(p==high),:,:]    \n",
    "    thetaLow = calc_theta(T[:,np.where(p==low),:,:], low)\n",
    "    thetaMid = calc_theta(T[:,np.where(p==med),:,:], med)\n",
    "    thetaHi = calc_theta(T[:,np.where(p==high),:,:], high)\n",
    "    \n",
    "    dTheta = thetaHi - thetaLow\n",
    "    dZ = geoHgtHigh - geoHgtLow\n",
    "    rootTerm = np.sqrt((gConst / thetaMid) * (dTheta / dZ))\n",
    "    outerTerm = (wVelHigh - wVelLow) / dZ\n",
    "    BI = 0.31 * (corPar / rootTerm) * (outerTerm) * 100000\n",
    "    \n",
    "    ml_BCI[:] = BI[:,0,0,:,:]       \n",
    "    \n",
    "    print(\"Calculating Upper Level Baroclinity\")\n",
    "    # Upper Level: 700, 500, 300\n",
    "    low = 700\n",
    "    med = 500\n",
    "    high = 300\n",
    "    \n",
    "    wVelLow = wVel[:,np.where(p==low),:,:]\n",
    "    wVelHigh = wVel[:,np.where(p==high),:,:]  \n",
    "    geoHgtLow = H[:,np.where(p==low),:,:]\n",
    "    geoHgtHigh = H[:,np.where(p==high),:,:]    \n",
    "    thetaLow = calc_theta(T[:,np.where(p==low),:,:], low)\n",
    "    thetaMid = calc_theta(T[:,np.where(p==med),:,:], med)\n",
    "    thetaHi = calc_theta(T[:,np.where(p==high),:,:], high)\n",
    "    \n",
    "    dTheta = thetaHi - thetaLow\n",
    "    dZ = geoHgtHigh - geoHgtLow\n",
    "    rootTerm = np.sqrt((gConst / thetaMid) * (dTheta / dZ))\n",
    "    outerTerm = (wVelHigh - wVelLow) / dZ    \n",
    "    BI = 0.31 * (corPar / rootTerm) * (outerTerm) * 100000\n",
    "    \n",
    "    ul_BCI[:] = BI[:,0,0,:,:]      \n",
    "    \n",
    "    print(\"Saving output NetCDF file baroclinic.\" + str(y) + \".nc\")\n",
    "\n",
    "    aTmp.close()\n",
    "    hTmp.close()\n",
    "    uTmp.close()\n",
    "    vTmp.close()  \n",
    "    newNCFile.close()\n",
    "    \n",
    "    print(\"Deleting temporary files\")\n",
    "    os.remove(dataPath + \"tmp.air.nc\")\n",
    "    os.remove(dataPath + \"tmp.hgt.nc\")\n",
    "    os.remove(dataPath + \"tmp.uwnd.nc\")\n",
    "    os.remove(dataPath + \"tmp.vwnd.nc\")\n",
    "\n",
    "ftp.quit()\n",
    "    \n",
    "print(\"Data generation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Analysis Calculation Code Block\n",
    "This code block handles all of the pre-analysis calculations. This mainly accesses the NetCDF files and sorts/stores the data into dictionaries that can be easily accessed in analysis steps for quick calculations and plotting routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "monthAnalysis = {}\n",
    "yearAnalysis = {}\n",
    "\n",
    "tmp_ll_mo = np.zeros((33,144))\n",
    "tmp_ml_mo = np.zeros((33,144))\n",
    "tmp_ul_mo = np.zeros((33,144))\n",
    "\n",
    "tmp_ll_yr = np.zeros((33,144))\n",
    "tmp_ml_yr = np.zeros((33,144))\n",
    "tmp_ul_yr = np.zeros((33,144))\n",
    "\n",
    "print(\"Begin pre-analysis calculations\")\n",
    "\n",
    "print(\"Calculating monthly and annual means\")\n",
    "for y in years:\n",
    "    print(\"Opening: \" + dataPath + \"baroclinic.\" + str(y) + \".nc\")\n",
    "    ncFile = Dataset(dataPath + \"baroclinic.\" + str(y) + \".nc\")\n",
    "    llOb = ncFile.variables['BCI_Low'][:,:,:]\n",
    "    mlOb = ncFile.variables['BCI_Mid'][:,:,:]\n",
    "    ulOb = ncFile.variables['BCI_Hi'][:,:,:]\n",
    "\n",
    "    llOb[np.isnan(llOb)] = 0\n",
    "    mlOb[np.isnan(mlOb)] = 0\n",
    "    ulOb[np.isnan(ulOb)] = 0        \n",
    "    \n",
    "    startPoint = 0\n",
    "    for m in range(1, 13):\n",
    "        mr = calendar.monthrange(y, m)       \n",
    "        if(m > 1):\n",
    "            mr_prev = calendar.monthrange(y, m-1)\n",
    "            dayCount = mr_prev[1]\n",
    "            startPoint += dayCount * hoursPerDay\n",
    "        \n",
    "        daysInMonth = mr[1]\n",
    "        endPoint = hoursPerDay * daysInMonth\n",
    "        obRange = range(startPoint, startPoint + endPoint)\n",
    "        obCount = len(obRange)    \n",
    "         \n",
    "        # Calculate Average for the Month\n",
    "        avg_ll = np.sum(llOb[startPoint:startPoint+endPoint,:,:], axis=0)\n",
    "        avg_ll = avg_ll / obCount\n",
    "        avg_ml = np.sum(mlOb[startPoint:startPoint+endPoint,:,:], axis=0)\n",
    "        avg_ml = avg_ml / obCount\n",
    "        avg_ul = np.sum(ulOb[startPoint:startPoint+endPoint,:,:], axis=0)\n",
    "        avg_ul = avg_ul / obCount\n",
    "        \n",
    "        key = \"low_month_\" + str(m) + \"_\" + str(y)\n",
    "        monthAnalysis[key] = avg_ll\n",
    "        key = \"mid_month_\" + str(m) + \"_\" + str(y)\n",
    "        monthAnalysis[key] = avg_ml\n",
    "        key = \"up_month_\" + str(m) + \"_\" + str(y)\n",
    "        monthAnalysis[key] = avg_ul    \n",
    "        \n",
    "    # Perform the Yearly Analysis\n",
    "    totalYObj = len(ncFile.dimensions[\"time\"])\n",
    "    avg_ll_y = np.sum(llOb[:,:,:], axis=0)\n",
    "    avg_ll_y = avg_ll_y / totalYObj\n",
    "    avg_ml_y = np.sum(mlOb[:,:,:], axis=0)\n",
    "    avg_ml_y = avg_ml_y / totalYObj\n",
    "    avg_ul_y = np.sum(ulOb[:,:,:], axis=0)\n",
    "    avg_ul_y = avg_ul_y / totalYObj  \n",
    "    \n",
    "    key = \"low_yr_\" + str(y)\n",
    "    yearAnalysis[key] = avg_ll_y\n",
    "    key = \"mid_yr_\" + str(y)\n",
    "    yearAnalysis[key] = avg_ml_y\n",
    "    key = \"up_yr_\" + str(y)\n",
    "    yearAnalysis[key] = avg_ul_y\n",
    "    \n",
    "    ncFile.close()\n",
    "    \n",
    "print(\"Calculating Standard Mean (1980 - 2010)\")\n",
    "standardMean = {}\n",
    "tmp1 = np.zeros((33,144))\n",
    "tmp2 = np.zeros((33,144))\n",
    "tmp3 = np.zeros((33,144))\n",
    "\n",
    "sT1 = []\n",
    "sT2 = []\n",
    "sT3 = []\n",
    "for i in range(1980, 2011):\n",
    "    tmp1 += yearAnalysis[\"low_yr_\" + str(i)]\n",
    "    tmp2 += yearAnalysis[\"mid_yr_\" + str(i)]\n",
    "    tmp3 += yearAnalysis[\"up_yr_\" + str(i)]\n",
    "    \n",
    "    sT1.append(yearAnalysis[\"low_yr_\" + str(i)])\n",
    "    sT2.append(yearAnalysis[\"mid_yr_\" + str(i)])\n",
    "    sT3.append(yearAnalysis[\"up_yr_\" + str(i)])\n",
    "    \n",
    "sigma_low = np.std(sT1)\n",
    "sigma_mid = np.std(sT2)\n",
    "sigma_hi = np.std(sT3)\n",
    "\n",
    "standardMean[\"low\"] = tmp1 / 30\n",
    "standardMean[\"mid\"] = tmp2 / 30\n",
    "standardMean[\"up\"] = tmp3 / 30    \n",
    "    \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Code Block\n",
    "This code block handles all of our analysis functions. Each code block will generate plots that will go into the defined plotting folder from the above constants code block.\n",
    "\n",
    "You can control which analysis(es) will be performed by modifying the boolean flags in the second code block near the top of this notebook, a quick rundown of what each flag does follows:\n",
    "\n",
    "* make_average_monthly_plots: Average monthly plots will calculate the average of the baroclinity for each month (IE: Dec 1 - Dec 31) in evey year and save it to the plotting folder.\n",
    "* make_average_yearly_plots: Average annual (Yearly) plots will calculate the average of the bacolinity for the full year (Jab 1 - Dec 31) and save the plots to the yearly plotting folder.\n",
    "* make_difference_plots: Difference plots will make two pairs of differences. The first are monthly differences, which compare one month's average to the same month in the previous year (IE: Jan 1950 - Jan 1949). The other is annual difference which compares one year's average to the previous (IE 1950 - 1949).\n",
    "* make_mean_compare_plots: This tool will compute the standard mean (Average baroclinity for 1980 - 2010) and then generate yearly difference plots between a given year's mean and the standard mean.\n",
    "* make_standard_anomaly_plots: This tool will calculate the standard anomaly between each year and the standard mean period (1980 - 2010), for more information on this, see: http://www.wpc.ncep.noaa.gov/hmt/ohrfc_training.ppt\n",
    "* make_moving_average_plots: Moving averages computes a thirty year average for one period and then moves forward to the next thirty years At the moment, only two of these can be generated due to the size of the data set.\n",
    "* make_moving_difference_plots: Moving differences performs the same moving average computation from the prior, but calculates the difference between these averages.\n",
    "\n",
    "Some of these processes are computationally expensive and will take some time to process so make sure to set the flag variables above prior to running this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(make_average_yearly_plots or make_average_monthly_plots):\n",
    "    for y in years:\n",
    "        if(make_average_monthly_plots):\n",
    "            for m in range(1, 13):             \n",
    "                mStr = str(\"0\") + str(m) if m < 10 else str(m)\n",
    "                plotTitle1 = \"Average Low-Level Baroclinity (\" + mStr + \" / \" + str(y) + \")\"\n",
    "                plotPath1 = p_avg_low_mo + monthPaths[m-1] + \"low_\" + mStr + \"-\" + str(y) + \".png\"\n",
    "                key = \"low_month_\" + str(m) + \"_\" + str(y)\n",
    "                avg_ll = monthAnalysis[key]\n",
    "                makeBCIPlot(avg_ll, plotTitle1, plotPath1)\n",
    "                \n",
    "                plotTitle1 = \"Average Mid-Level Baroclinity (\" + mStr + \" / \" + str(y) + \")\"\n",
    "                plotPath1 = p_avg_mid_mo + monthPaths[m-1] + \"mid_\" + mStr + \"-\" + str(y) + \".png\"\n",
    "                key = \"mid_month_\" + str(m) + \"_\" + str(y)\n",
    "                avg_ml = monthAnalysis[key]                \n",
    "                makeBCIPlot(avg_ml, plotTitle1, plotPath1)\n",
    "                \n",
    "                plotTitle1 = \"Average Upper-Level Baroclinity (\" + mStr + \" / \" +  str(y) + \")\"\n",
    "                plotPath1 = p_avg_up_mo + monthPaths[m-1] + \"upper_\" + mStr + \"-\" + str(y) + \".png\"\n",
    "                key = \"up_month_\" + str(m) + \"_\" + str(y)\n",
    "                avg_ul = monthAnalysis[key]                 \n",
    "                makeBCIPlot(avg_ul, plotTitle1, plotPath1)           \n",
    "\n",
    "        if(make_average_yearly_plots):\n",
    "            key = \"low_yr_\" + str(y)\n",
    "            avg_ll_y = yearAnalysis[key]\n",
    "            key = \"mid_yr_\" + str(y)\n",
    "            avg_ml_y = yearAnalysis[key] \n",
    "            key = \"up_yr_\" + str(y)\n",
    "            avg_ul_y = yearAnalysis[key]            \n",
    "            \n",
    "            plotTitle1 = \"Average Low-Level Baroclinity (\" + str(y) + \")\"\n",
    "            plotPath1 = p_avg_low_ye + \"low_y-\" + str(y) + \".png\"\n",
    "            makeBCIPlot(avg_ll_y, plotTitle1, plotPath1)\n",
    "            plotTitle1 = \"Average Mid-Level Baroclinity (\" + str(y) + \")\"\n",
    "            plotPath1 = p_avg_mid_ye + \"mid_y-\" + str(y) + \".png\"\n",
    "            makeBCIPlot(avg_ml_y, plotTitle1, plotPath1)\n",
    "            plotTitle1 = \"Average Upper-Level Baroclinity (\" +  str(y) + \")\"\n",
    "            plotPath1 = p_avg_up_ye + \"upper_y-\" + str(y) + \".png\"\n",
    "            makeBCIPlot(avg_ul_y, plotTitle1, plotPath1)    \n",
    "    \n",
    "# Analysis 1/2: Difference Plots\n",
    "# D_Month\n",
    "if(make_difference_plots):\n",
    "    for m in range(1, 13):\n",
    "        for y in years:\n",
    "            if(y > 1948):\n",
    "                prior_low = \"low_month_\" + str(m) + \"_\" + str(y-1)\n",
    "                now_low = \"low_month_\" + str(m) + \"_\" + str(y)\n",
    "                prior_mid = \"mid_month_\" + str(m) + \"_\" + str(y-1)\n",
    "                now_mid = \"mid_month_\" + str(m) + \"_\" + str(y)\n",
    "                prior_up = \"up_month_\" + str(m) + \"_\" + str(y-1)\n",
    "                now_up = \"up_month_\" + str(m) + \"_\" + str(y)     \n",
    "\n",
    "                bl_prior = monthAnalysis[prior_low]\n",
    "                bl_now = monthAnalysis[now_low]\n",
    "                bm_prior = monthAnalysis[prior_mid]\n",
    "                bm_now = monthAnalysis[now_mid]\n",
    "                bu_prior = monthAnalysis[prior_up]\n",
    "                bu_now = monthAnalysis[now_up]  \n",
    "\n",
    "                pathLow = p_d_low_mo + monthPaths[m-1] + \"d_low_\" + str(m) + \"_\" + str(y-1) + \"-\" + str(y) + \".png\"\n",
    "                plotTitle1 = \"Low-Level Baroclinity Difference (\" + str(m) + \"/\" + str(y) + \" - \" + str(m) + \"/\" + str(y-1) + \")\"\n",
    "                make_D_BCIPlot(bl_prior, bl_now, plotTitle1, pathLow)\n",
    "                pathLow = p_d_mid_mo + monthPaths[m-1] + \"d_mid_\" + str(m) + \"_\" + str(y-1) + \"-\" + str(y) + \".png\"\n",
    "                plotTitle1 = \"Mid-Level Baroclinity Difference (\" + str(m) + \"/\" + str(y) + \" - \" + str(m) + \"/\" + str(y-1) + \")\"\n",
    "                make_D_BCIPlot(bm_prior, bm_now, plotTitle1, pathLow)\n",
    "                pathLow = p_d_up_mo + monthPaths[m-1] + \"d_up_\" + str(m) + \"_\" + str(y-1) + \"-\" + str(y) + \".png\"\n",
    "                plotTitle1 = \"Upper-Level Baroclinity Difference (\" + str(m) + \"/\" + str(y) + \" - \" + str(m) + \"/\" + str(y-1) + \")\"\n",
    "                make_D_BCIPlot(bu_prior, bu_now, plotTitle1, pathLow)                   \n",
    "    \n",
    "# D_Year    \n",
    "    for y in years:\n",
    "        if(y > 1948):\n",
    "            prior_low = \"low_yr_\" + str(y-1)\n",
    "            now_low = \"low_yr_\" + str(y)\n",
    "            prior_mid = \"mid_yr_\" + str(y-1)\n",
    "            now_mid = \"mid_yr_\" + str(y)\n",
    "            prior_up = \"up_yr_\" + str(y-1)\n",
    "            now_up = \"up_yr_\" + str(y)\n",
    "\n",
    "            bl_prior = yearAnalysis[prior_low]\n",
    "            bl_now = yearAnalysis[now_low]\n",
    "            bm_prior = yearAnalysis[prior_mid]\n",
    "            bm_now = yearAnalysis[now_mid]\n",
    "            bu_prior = yearAnalysis[prior_up]\n",
    "            bu_now = yearAnalysis[now_up]\n",
    "\n",
    "            pathLow = p_d_low_ye + \"d_low_\" + str(y-1) + \"-\" + str(y) + \".png\"\n",
    "            plotTitle1 = \"Low-Level Baroclinity Difference (\" + str(y) + \" - \" + str(y-1) + \")\"\n",
    "            make_D_BCIPlot(bl_prior, bl_now, plotTitle1, pathLow)\n",
    "            pathLow = p_d_mid_ye + \"d_mid_\" + str(y-1) + \"-\" + str(y) + \".png\"\n",
    "            plotTitle1 = \"Mid-Level Baroclinity Difference (\" + str(y) + \" - \" + str(y-1) + \")\"\n",
    "            make_D_BCIPlot(bm_prior, bm_now, plotTitle1, pathLow)\n",
    "            pathLow = p_d_up_ye + \"d_up_\" + str(y-1) + \"-\" + str(y) + \".png\"\n",
    "            plotTitle1 = \"Upper-Level Baroclinity Difference (\" + str(y) + \" - \" + str(y-1) + \")\"\n",
    "            make_D_BCIPlot(bu_prior, bu_now, plotTitle1, pathLow)            \n",
    "    \n",
    "# Analysis 3:\n",
    "# Anomaly Plots (Comparing to 1980 - 2010 \"Mean\")\n",
    "\n",
    "\n",
    "for y in years:\n",
    "    low = yearAnalysis[\"low_yr_\" + str(y)]\n",
    "    mid = yearAnalysis[\"mid_yr_\" + str(y)]\n",
    "    up = yearAnalysis[\"up_yr_\" + str(y)]\n",
    "    \n",
    "    if(make_mean_compare_plots):\n",
    "        plotTitle = \"Difference of \" + str(y) + \" Low-Level Baroclinity to 1980-2010 Mean\"# (Dashed Significant to 1%)\" \n",
    "        savePath = p_mean_c_l + \"low_mean_comp_\" + str(y) + \".png\"\n",
    "        make_mean_compare_BCIPlot(standardMean[\"low\"], low, plotTitle, savePath, withStats=False)\n",
    "        plotTitle = \"Difference of \" + str(y) + \" Mid-Level Baroclinity to 1980-2010 Mean\"# (Dashed Significant to 1%)\" \n",
    "        savePath = p_mean_c_m + \"mid_mean_comp_\" + str(y) + \".png\"\n",
    "        make_mean_compare_BCIPlot(standardMean[\"mid\"], mid, plotTitle, savePath, withStats=False)\n",
    "        plotTitle = \"Difference of \" + str(y) + \" Upper-Level Baroclinity to 1980-2010 Mean\"# (Dashed Significant to 1%)\" \n",
    "        savePath = p_mean_c_u + \"up_mean_comp_\" + str(y) + \".png\"\n",
    "        make_mean_compare_BCIPlot(standardMean[\"up\"], up, plotTitle, savePath, withStats=False)\n",
    "    \n",
    "    if(make_standard_anomaly_plots):\n",
    "        anom_low = (low - standardMean[\"low\"]) / sigma_low\n",
    "        anom_mid = (mid - standardMean[\"mid\"]) / sigma_mid\n",
    "        anom_up = (up - standardMean[\"up\"]) / sigma_hi\n",
    "\n",
    "        plotTitle = \"Standard Anomaly of Low-Level Baroclinity (\" + str(y) + \") (Comp. 1980-2010 Mean)\"\n",
    "        plotSavePath = p_anom_low + \"low_anom_\" + str(y) + \".png\"\n",
    "        make_anom_BCIPlot(anom_low, plotTitle, plotSavePath)\n",
    "        plotTitle = \"Standard Anomaly of Mid-Level Baroclinity (\" + str(y) + \") (Comp. 1980-2010 Mean)\"\n",
    "        plotSavePath = p_anom_mid + \"mid_anom_\" + str(y) + \".png\"\n",
    "        make_anom_BCIPlot(anom_mid, plotTitle, plotSavePath)\n",
    "        plotTitle = \"Standard Anomaly of Upper-Level Baroclinity (\" + str(y) + \") (Comp. 1980-2010 Mean)\"\n",
    "        plotSavePath = p_anom_up + \"up_anom_\" + str(y) + \".png\"\n",
    "        make_anom_BCIPlot(anom_up, plotTitle, plotSavePath) \n",
    "        \n",
    "# Analysis 4: Moving Averages\n",
    "if(make_moving_average_plots):\n",
    "    for m in range(1, 13):\n",
    "        mStr = str(\"0\") + str(m) if m < 10 else str(m)\n",
    "        for y in years:\n",
    "            if((y + 30) < 2018):\n",
    "                totl = np.zeros((33,144))\n",
    "                totm = np.zeros((33,144))\n",
    "                totu = np.zeros((33,144))\n",
    "                for i in range(y, y+31):\n",
    "                    totl += monthAnalysis[\"low_month_\" + str(m) + \"_\" + str(i)]\n",
    "                    totm += monthAnalysis[\"mid_month_\" + str(m) + \"_\" + str(i)]\n",
    "                    totu += monthAnalysis[\"up_month_\" + str(m) + \"_\" + str(i)]\n",
    "                # Compute Average\n",
    "                totl /= 30\n",
    "                totm /= 30\n",
    "                totu /= 30\n",
    "                # Plot\n",
    "                plotTitle1 = \"Moving Average Low-Level Baroclinity ((\" + mStr + \") - \" + str(y) + \" - \" + str(y+30) + \")\"\n",
    "                plotPath1 = p_mov_low + monthPaths[m-1] + \"mavg_low_\" + mStr + \"-\" + str(y) + \"-\" + str(y+30) + \".png\"\n",
    "                makeBCIPlot(totl, plotTitle1, plotPath1)            \n",
    "                plotTitle1 = \"Moving Average Mid-Level Baroclinity ((\" + mStr + \") - \" + str(y) + \" - \" + str(y+30) + \")\"\n",
    "                plotPath1 = p_mov_mid + monthPaths[m-1] + \"mavg_mid_\" + mStr + \"-\" + str(y) + \"-\" + str(y+30) + \".png\"\n",
    "                makeBCIPlot(totm, plotTitle1, plotPath1)     \n",
    "                plotTitle1 = \"Moving Average Upper-Level Baroclinity ((\" + mStr + \") - \" + str(y) + \" - \" + str(y+30) + \")\"\n",
    "                plotPath1 = p_mov_up + monthPaths[m-1] + \"mavg_up_\" + mStr + \"-\" + str(y) + \"-\" + str(y+30) + \".png\"\n",
    "                makeBCIPlot(totu, plotTitle1, plotPath1)      \n",
    "                \n",
    "if(make_moving_difference_plots):\n",
    "    for m in range(1, 13):\n",
    "        mStr = str(\"0\") + str(m) if m < 10 else str(m)\n",
    "        y = years[0]\n",
    "        while(True):\n",
    "            print(\"Plotting for \" + str(y))\n",
    "            if((y + 20) < 2018-20):\n",
    "                totl_before = np.zeros((33,144))\n",
    "                totm_before = np.zeros((33,144))\n",
    "                totu_before = np.zeros((33,144))                \n",
    "                totl_after = np.zeros((33,144))\n",
    "                totm_after = np.zeros((33,144))\n",
    "                totu_after = np.zeros((33,144)) \n",
    "                \n",
    "                for i in range(y, y+21):\n",
    "                    totl_before += monthAnalysis[\"low_month_\" + str(m) + \"_\" + str(i)]\n",
    "                    totm_before += monthAnalysis[\"mid_month_\" + str(m) + \"_\" + str(i)]\n",
    "                    totu_before += monthAnalysis[\"up_month_\" + str(m) + \"_\" + str(i)] \n",
    "                totl_before /= 20\n",
    "                totm_before /= 20\n",
    "                totu_before /= 20\n",
    "                for i in range(y+20, y+41):\n",
    "                    totl_after += monthAnalysis[\"low_month_\" + str(m) + \"_\" + str(i)]\n",
    "                    totm_after += monthAnalysis[\"mid_month_\" + str(m) + \"_\" + str(i)]\n",
    "                    totu_after += monthAnalysis[\"up_month_\" + str(m) + \"_\" + str(i)]                                   \n",
    "                totl_after /= 20\n",
    "                totm_after /= 20\n",
    "                totu_after /= 20\n",
    "                    \n",
    "                plotTitle1 = \"Average Low-Level Baroclinity ([\" + mStr + \"] \" + str(y+40) + \" - \" + str(y+20) + \" - \" + str(y+20) + \" - \" + str(y) + \")\"\n",
    "                pathLow = p_dmov_low + monthPaths[m-1] + \"dmavg_low_\" + str(y+40) + \"-\" + str(y) + \".png\"\n",
    "                make_D_BCIPlot(totl_before, totl_after, plotTitle1, pathLow)\n",
    "                plotTitle1 = \"Average Mid-Level Baroclinity ([\" + mStr + \"] \" + str(y+40) + \" - \" + str(y+20) + \" - \" + str(y+20) + \" - \" + str(y) + \")\"\n",
    "                pathLow = p_dmov_mid + monthPaths[m-1] + \"dmavg_mid_\" + str(y+40) + \"-\" + str(y) + \".png\"\n",
    "                make_D_BCIPlot(totm_before, totm_after, plotTitle1, pathLow)\n",
    "                plotTitle1 = \"Average Upper-Level Baroclinity ([\" + mStr + \"] \" + str(y+40) + \" - \" + str(y+20) + \" - \" + str(y+20) + \" - \" + str(y) + \")\"\n",
    "                pathLow = p_dmov_up + monthPaths[m-1] + \"dmavg_up_\" + str(y+40) + \"-\" + str(y) + \".png\"\n",
    "                make_D_BCIPlot(totu_before, totu_after, plotTitle1, pathLow)   \n",
    "                \n",
    "                y += 20\n",
    "            elif((y + 20) == 1998):\n",
    "                totl_before = np.zeros((33,144))\n",
    "                totm_before = np.zeros((33,144))\n",
    "                totu_before = np.zeros((33,144))                \n",
    "                totl_after = np.zeros((33,144))\n",
    "                totm_after = np.zeros((33,144))\n",
    "                totu_after = np.zeros((33,144)) \n",
    "                \n",
    "                for i in range(y, y+21):\n",
    "                    totl_before += monthAnalysis[\"low_month_\" + str(m) + \"_\" + str(i)]\n",
    "                    totm_before += monthAnalysis[\"mid_month_\" + str(m) + \"_\" + str(i)]\n",
    "                    totu_before += monthAnalysis[\"up_month_\" + str(m) + \"_\" + str(i)] \n",
    "                totl_before /= 20\n",
    "                totm_before /= 20\n",
    "                totu_before /= 20\n",
    "                for i in range(y+20, y+40):\n",
    "                    totl_after += monthAnalysis[\"low_month_\" + str(m) + \"_\" + str(i)]\n",
    "                    totm_after += monthAnalysis[\"mid_month_\" + str(m) + \"_\" + str(i)]\n",
    "                    totu_after += monthAnalysis[\"up_month_\" + str(m) + \"_\" + str(i)]                                   \n",
    "                totl_after /= 19\n",
    "                totm_after /= 19\n",
    "                totu_after /= 19\n",
    "                    \n",
    "                plotTitle1 = \"Average Low-Level Baroclinity ([\" + mStr + \"] \" + str(y+39) + \" - \" + str(y+20) + \" - \" + str(y+20) + \" - \" + str(y) + \")\"\n",
    "                pathLow = p_dmov_low + monthPaths[m-1] + \"dmavg_low_\" + str(y+39) + \"-\" + str(y) + \".png\"\n",
    "                make_D_BCIPlot(totl_before, totl_after, plotTitle1, pathLow)\n",
    "                plotTitle1 = \"Average Mid-Level Baroclinity ([\" + mStr + \"] \" + str(y+39) + \" - \" + str(y+20) + \" - \" + str(y+20) + \" - \" + str(y) + \")\"\n",
    "                pathLow = p_dmov_mid + monthPaths[m-1] + \"dmavg_mid_\" + str(y+39) + \"-\" + str(y) + \".png\"\n",
    "                make_D_BCIPlot(totm_before, totm_after, plotTitle1, pathLow)\n",
    "                plotTitle1 = \"Average Upper-Level Baroclinity ([\" + mStr + \"] \" + str(y+39) + \" - \" + str(y+20) + \" - \" + str(y+20) + \" - \" + str(y) + \")\"\n",
    "                pathLow = p_dmov_up + monthPaths[m-1] + \"dmavg_up_\" + str(y+39) + \"-\" + str(y) + \".png\"\n",
    "                make_D_BCIPlot(totu_before, totu_after, plotTitle1, pathLow)   \n",
    "                \n",
    "                y += 20                \n",
    "            else:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclaneous Code Blocks\n",
    "Anything that I'm testing, or keeping as a reference for future additions are kept down here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading air temperature, storing in tmp.air.nc\n",
      "Downloading height, storing in tmp.hgt.nc\n",
      "Downloading u winds, storing in tmp.uwnd.nc\n",
      "Downloading v winds, storing in tmp.vwnd.nc\n",
      "Downloads complete, opening netCDF files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:77: RuntimeWarning: invalid value encountered in sqrt\n",
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:79: RuntimeWarning: divide by zero encountered in divide\n",
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:79: RuntimeWarning: invalid value encountered in multiply\n",
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:92: RuntimeWarning: invalid value encountered in sqrt\n",
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:94: RuntimeWarning: divide by zero encountered in divide\n",
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:122: RuntimeWarning: invalid value encountered in sqrt\n",
      "D:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:124: RuntimeWarning: divide by zero encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting temporary files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'221 Goodbye.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftp = FTP('ftp.cdc.noaa.gov')\n",
    "ftp.login()\n",
    "\n",
    "tLink = \"/Datasets/ncep.reanalysis/pressure/air.2018.nc\"\n",
    "hLink = \"/Datasets/ncep.reanalysis/pressure/hgt.2018.nc\"\n",
    "uLink = \"/Datasets/ncep.reanalysis/pressure/uwnd.2018.nc\"\n",
    "vLink = \"/Datasets/ncep.reanalysis/pressure/vwnd.2018.nc\" \n",
    "\n",
    "print(\"Downloading air temperature, storing in tmp.air.nc\")\n",
    "\n",
    "localfile1 = open(dataPath + \"tmp.air.nc\", 'wb')\n",
    "ftp.retrbinary('RETR ' + tLink, localfile1.write, 1024)\n",
    "localfile1.close()    \n",
    "\n",
    "print(\"Downloading height, storing in tmp.hgt.nc\")\n",
    "localfile2 = open(dataPath + \"tmp.hgt.nc\", 'wb')\n",
    "ftp.retrbinary('RETR ' + hLink, localfile2.write, 1024)\n",
    "localfile2.close() \n",
    "\n",
    "print(\"Downloading u winds, storing in tmp.uwnd.nc\")\n",
    "localfile3 = open(dataPath + \"tmp.uwnd.nc\", 'wb')\n",
    "ftp.retrbinary('RETR ' + uLink, localfile3.write, 1024)\n",
    "localfile3.close() \n",
    "\n",
    "print(\"Downloading v winds, storing in tmp.vwnd.nc\")\n",
    "localfile4 = open(dataPath + \"tmp.vwnd.nc\", 'wb')\n",
    "ftp.retrbinary('RETR ' + vLink, localfile4.write, 1024)\n",
    "localfile4.close() \n",
    "\n",
    "print(\"Downloads complete, opening netCDF files\")\n",
    "\n",
    "aTmp = Dataset(dataPath + \"tmp.air.nc\")\n",
    "hTmp = Dataset(dataPath + \"tmp.hgt.nc\")\n",
    "uTmp = Dataset(dataPath + \"tmp.uwnd.nc\")\n",
    "vTmp = Dataset(dataPath + \"tmp.vwnd.nc\")\n",
    "\n",
    "outFile = dataPath + \"baroclinic.test.nc\"\n",
    "newNCFile = Dataset(outFile, 'w', format='NETCDF4_CLASSIC')\n",
    "time = newNCFile.createDimension('time', size=None) \n",
    "lat = newNCFile.createDimension('lat', 33)\n",
    "lon = newNCFile.createDimension('lon', 144)  \n",
    "\n",
    "ll_BCI = newNCFile.createVariable('BCI_925-850', np.float32, ('time','lat','lon'))\n",
    "ml_BCI = newNCFile.createVariable('BCI_850-700', np.float32, ('time','lat','lon'))   \n",
    "ul_BCI = newNCFile.createVariable('BCI_700-500', np.float32, ('time','lat','lon'))  \n",
    "tl_BCI = newNCFile.createVariable('BCI_500-300', np.float32, ('time','lat','lon'))\n",
    "\n",
    "T = np.squeeze(aTmp.variables['air'][:,:,2:35,:]) \n",
    "U = np.squeeze(uTmp.variables['uwnd'][:,:,2:35,:])\n",
    "V = np.squeeze(vTmp.variables['vwnd'][:,:,2:35,:])\n",
    "H = np.squeeze(hTmp.variables['hgt'][:,:,2:35,:])\n",
    "wVel = (U**2 + V**2)**0.5\n",
    "\n",
    "lat = np.linspace(5,85,33)\n",
    "lon = np.linspace(-177.5,180,144)\n",
    "p = aTmp.variables['level'][:] # Grab the isobaric levels\n",
    "\n",
    "itime = len(aTmp.variables['time'][:]) \n",
    "ilat = len(lat)\n",
    "ilon = len(lon)    \n",
    "\n",
    "f = TwoOmega * np.sin(lat * (np.pi / 180))\n",
    "# Construct a \"coriolis\" array of equivalent size to the other arrays\n",
    "corPar = np.zeros((itime, 1, 1, ilat, ilon))\n",
    "for i,l in enumerate(lat):\n",
    "    corPar[:,0,0,i,:] = f[np.where(lat == l)]\n",
    "#    \n",
    "wVelLow = wVel[:,np.where(p==925),:,:]\n",
    "wVelHigh = wVel[:,np.where(p==850),:,:]  \n",
    "geoHgtLow = H[:,np.where(p==925),:,:]\n",
    "geoHgtHigh = H[:,np.where(p==850),:,:]    \n",
    "thetaLow = calc_theta(T[:,np.where(p==925),:,:], 925)\n",
    "thetaHi = calc_theta(T[:,np.where(p==850),:,:], 850)\n",
    "\n",
    "dLogTheta = np.log(thetaHi) - np.log(thetaLow)\n",
    "dZ = geoHgtHigh - geoHgtLow\n",
    "rootTerm = np.sqrt((gConst) * (dLogTheta / dZ))\n",
    "outerTerm = (wVelHigh - wVelLow) / dZ  \n",
    "BI = 0.31 * (corPar / rootTerm) * (outerTerm) * 100000    \n",
    "ll_BCI[:] = BI[:,0,0,:,:] \n",
    "\n",
    "#\n",
    "wVelLow = wVel[:,np.where(p==850),:,:]\n",
    "wVelHigh = wVel[:,np.where(p==700),:,:]  \n",
    "geoHgtLow = H[:,np.where(p==850),:,:]\n",
    "geoHgtHigh = H[:,np.where(p==700),:,:]    \n",
    "thetaLow = calc_theta(T[:,np.where(p==850),:,:], 850)\n",
    "thetaHi = calc_theta(T[:,np.where(p==700),:,:], 700)\n",
    "\n",
    "dLogTheta = np.log(thetaHi) - np.log(thetaLow)\n",
    "dZ = geoHgtHigh - geoHgtLow\n",
    "rootTerm = np.sqrt((gConst) * (dLogTheta / dZ))\n",
    "outerTerm = (wVelHigh - wVelLow) / dZ  \n",
    "BI = 0.31 * (corPar / rootTerm) * (outerTerm) * 100000    \n",
    "ml_BCI[:] = BI[:,0,0,:,:]  \n",
    "\n",
    "#\n",
    "wVelLow = wVel[:,np.where(p==700),:,:]\n",
    "wVelHigh = wVel[:,np.where(p==500),:,:]  \n",
    "geoHgtLow = H[:,np.where(p==700),:,:]\n",
    "geoHgtHigh = H[:,np.where(p==500),:,:]    \n",
    "thetaLow = calc_theta(T[:,np.where(p==700),:,:], 700)\n",
    "thetaHi = calc_theta(T[:,np.where(p==500),:,:], 500)\n",
    "\n",
    "dLogTheta = np.log(thetaHi) - np.log(thetaLow)\n",
    "dZ = geoHgtHigh - geoHgtLow\n",
    "rootTerm = np.sqrt((gConst) * (dLogTheta / dZ))\n",
    "outerTerm = (wVelHigh - wVelLow) / dZ  \n",
    "BI = 0.31 * (corPar / rootTerm) * (outerTerm) * 100000    \n",
    "ul_BCI[:] = BI[:,0,0,:,:] \n",
    "\n",
    "#\n",
    "wVelLow = wVel[:,np.where(p==500),:,:]\n",
    "wVelHigh = wVel[:,np.where(p==300),:,:]  \n",
    "geoHgtLow = H[:,np.where(p==500),:,:]\n",
    "geoHgtHigh = H[:,np.where(p==300),:,:]    \n",
    "thetaLow = calc_theta(T[:,np.where(p==500),:,:], 500)\n",
    "thetaHi = calc_theta(T[:,np.where(p==300),:,:], 300)\n",
    "\n",
    "dLogTheta = np.log(thetaHi) - np.log(thetaLow)\n",
    "dZ = geoHgtHigh - geoHgtLow\n",
    "rootTerm = np.sqrt((gConst) * (dLogTheta / dZ))\n",
    "outerTerm = (wVelHigh - wVelLow) / dZ  \n",
    "BI = 0.31 * (corPar / rootTerm) * (outerTerm) * 100000    \n",
    "tl_BCI[:] = BI[:,0,0,:,:] \n",
    "\n",
    "aTmp.close()\n",
    "hTmp.close()\n",
    "uTmp.close()\n",
    "vTmp.close()  \n",
    "newNCFile.close()\n",
    "\n",
    "print(\"Deleting temporary files\")\n",
    "os.remove(dataPath + \"tmp.air.nc\")\n",
    "os.remove(dataPath + \"tmp.hgt.nc\")\n",
    "os.remove(dataPath + \"tmp.uwnd.nc\")\n",
    "os.remove(dataPath + \"tmp.vwnd.nc\")\n",
    "\n",
    "ftp.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
